{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "pd.options.display.max_rows = 20\n",
    "sns.set(style=\"darkgrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiffanysung/anaconda2/envs/py36/lib/python2.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane = np.load('/Users/tiffanysung/Documents/APM/reduce/airplane.npy')\n",
    "alarmclock = np.load('/Users/tiffanysung/Documents/APM/reduce/alarm clock.npy')\n",
    "ambulance = np.load('/Users/tiffanysung/Documents/APM/reduce/ambulance.npy')\n",
    "angel = np.load('/Users/tiffanysung/Documents/APM/reduce/angel.npy')\n",
    "animalmigration = np.load('/Users/tiffanysung/Documents/APM/reduce/animal migration.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "airplane = np.c_[airplane, np.zeros(len(airplane))]\n",
    "alarmclock = np.c_[alarmclock, np.ones(len(alarmclock))]\n",
    "ambulance = np.c_[ambulance, 2*np.ones(len(ambulance))]\n",
    "angel = np.c_[angel, 3*np.ones(len(angel))]\n",
    "animalmigration = np.c_[animalmigration, 4*np.ones(len(animalmigration))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the label codes in a dictionary\n",
    "label_dict = {0:'airplane', 1:'alarmclock', 2:'ambulance', 3:'angel', 4:'animalmigration'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151623, 785)\n",
      "(123399, 785)\n",
      "(148004, 785)\n",
      "(149736, 785)\n",
      "(137847, 785)\n"
     ]
    }
   ],
   "source": [
    "print (airplane.shape)\n",
    "print (alarmclock.shape)\n",
    "print (ambulance.shape)\n",
    "print (angel.shape)\n",
    "print (animalmigration.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, further split our reduce dataset into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((airplane[:10000,:-1], alarmclock[:10000,:-1], ambulance[:10000,:-1], angel[:10000,:-1], animalmigration[:10000,:-1]), axis=0).astype('float32') # all columns but the lastt\n",
    "y = np.concatenate((airplane[:10000,-1], alarmclock[:10000,-1], ambulance[:10000,-1], angel[:10000,-1], animalmigration[:10000,-1]), axis=0).astype('float32') # the last column\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X/255.,y,test_size=0.5,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 903 ms, total: 1min 20s\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parameters = {'n_estimators': [10,20,40,60,80,100,120,140,160]}\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_jobs=-1, random_state=0)\n",
    "rf = GridSearchCV(clf_rf, parameters, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "results = pd.DataFrame(rf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.653950</td>\n",
       "      <td>0.265854</td>\n",
       "      <td>0.83548</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>160</td>\n",
       "      <td>{u'n_estimators': 160}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.832333</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.833533</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.050225</td>\n",
       "      <td>0.012557</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26.989686</td>\n",
       "      <td>0.290116</td>\n",
       "      <td>0.83408</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>140</td>\n",
       "      <td>{u'n_estimators': 140}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.838412</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.831853</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.831973</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.675612</td>\n",
       "      <td>0.066238</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.025324</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.83292</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>120</td>\n",
       "      <td>{u'n_estimators': 120}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.839851</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.829453</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.256545</td>\n",
       "      <td>0.048716</td>\n",
       "      <td>0.004902</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.281218</td>\n",
       "      <td>0.136384</td>\n",
       "      <td>0.83176</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>100</td>\n",
       "      <td>{u'n_estimators': 100}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.838052</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830053</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.827172</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.269152</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.769533</td>\n",
       "      <td>0.151273</td>\n",
       "      <td>0.82792</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>80</td>\n",
       "      <td>{u'n_estimators': 80}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.832893</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.823452</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.827412</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.426165</td>\n",
       "      <td>0.008829</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.335266</td>\n",
       "      <td>0.139150</td>\n",
       "      <td>0.82464</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>60</td>\n",
       "      <td>{u'n_estimators': 60}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.830734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821171</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.822012</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.517515</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>0.004324</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.439294</td>\n",
       "      <td>0.132949</td>\n",
       "      <td>0.81604</td>\n",
       "      <td>0.99996</td>\n",
       "      <td>40</td>\n",
       "      <td>{u'n_estimators': 40}</td>\n",
       "      <td>7</td>\n",
       "      <td>0.822817</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.813730</td>\n",
       "      <td>0.99994</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.99994</td>\n",
       "      <td>0.292428</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.004873</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.233324</td>\n",
       "      <td>0.130276</td>\n",
       "      <td>0.79540</td>\n",
       "      <td>0.99964</td>\n",
       "      <td>20</td>\n",
       "      <td>{u'n_estimators': 20}</td>\n",
       "      <td>8</td>\n",
       "      <td>0.801464</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.791047</td>\n",
       "      <td>0.99976</td>\n",
       "      <td>0.793687</td>\n",
       "      <td>0.99940</td>\n",
       "      <td>0.134600</td>\n",
       "      <td>0.002297</td>\n",
       "      <td>0.004422</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.015711</td>\n",
       "      <td>0.191050</td>\n",
       "      <td>0.75796</td>\n",
       "      <td>0.99538</td>\n",
       "      <td>10</td>\n",
       "      <td>{u'n_estimators': 10}</td>\n",
       "      <td>9</td>\n",
       "      <td>0.759717</td>\n",
       "      <td>0.995379</td>\n",
       "      <td>0.753841</td>\n",
       "      <td>0.99532</td>\n",
       "      <td>0.760322</td>\n",
       "      <td>0.99544</td>\n",
       "      <td>0.064985</td>\n",
       "      <td>0.050388</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "8      23.653950         0.265854          0.83548           1.00000   \n",
       "7      26.989686         0.290116          0.83408           1.00000   \n",
       "6      24.025324         0.165225          0.83292           1.00000   \n",
       "5      19.281218         0.136384          0.83176           1.00000   \n",
       "4      14.769533         0.151273          0.82792           1.00000   \n",
       "3      10.335266         0.139150          0.82464           1.00000   \n",
       "2       5.439294         0.132949          0.81604           0.99996   \n",
       "1       2.233324         0.130276          0.79540           0.99964   \n",
       "0       1.015711         0.191050          0.75796           0.99538   \n",
       "\n",
       "  param_n_estimators                  params  rank_test_score  \\\n",
       "8                160  {u'n_estimators': 160}                1   \n",
       "7                140  {u'n_estimators': 140}                2   \n",
       "6                120  {u'n_estimators': 120}                3   \n",
       "5                100  {u'n_estimators': 100}                4   \n",
       "4                 80   {u'n_estimators': 80}                5   \n",
       "3                 60   {u'n_estimators': 60}                6   \n",
       "2                 40   {u'n_estimators': 40}                7   \n",
       "1                 20   {u'n_estimators': 20}                8   \n",
       "0                 10   {u'n_estimators': 10}                9   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "8           0.840571            1.000000           0.832333   \n",
       "7           0.838412            1.000000           0.831853   \n",
       "6           0.839851            1.000000           0.829453   \n",
       "5           0.838052            1.000000           0.830053   \n",
       "4           0.832893            1.000000           0.823452   \n",
       "3           0.830734            1.000000           0.821171   \n",
       "2           0.822817            1.000000           0.813730   \n",
       "1           0.801464            0.999760           0.791047   \n",
       "0           0.759717            0.995379           0.753841   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "8             1.00000           0.833533             1.00000      3.050225   \n",
       "7             1.00000           0.831973             1.00000      0.675612   \n",
       "6             1.00000           0.829453             1.00000      0.256545   \n",
       "5             1.00000           0.827172             1.00000      0.269152   \n",
       "4             1.00000           0.827412             1.00000      0.426165   \n",
       "3             1.00000           0.822012             1.00000      0.517515   \n",
       "2             0.99994           0.811570             0.99994      0.292428   \n",
       "1             0.99976           0.793687             0.99940      0.134600   \n",
       "0             0.99532           0.760322             0.99544      0.064985   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "8        0.012557        0.003634         0.000000  \n",
       "7        0.066238        0.003064         0.000000  \n",
       "6        0.048716        0.004902         0.000000  \n",
       "5        0.002540        0.004603         0.000000  \n",
       "4        0.008829        0.003871         0.000000  \n",
       "3        0.005071        0.004324         0.000000  \n",
       "2        0.001404        0.004873         0.000028  \n",
       "1        0.002297        0.004422         0.000170  \n",
       "0        0.050388        0.002923         0.000049  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.sort_values('mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "results.plot('param_n_estimators','mean_test_score');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('random forest accuracy: ', 0.82912)\n",
      "CPU times: user 22.5 s, sys: 203 ms, total: 22.7 s\n",
      "Wall time: 3.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=0)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print ('random forest accuracy: ',acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "tuning_parameters = {'n_neighbors': [1,3,5,7,9,11]}\n",
    "\n",
    "clf_knn = KNeighborsClassifier(n_jobs=-1)\n",
    "knn = GridSearchCV(clf_knn, tuning_parameters, n_jobs=-1)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "results_knn = pd.DataFrame(knn.cv_results_)\n",
    "results_knn.sort_values('mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNN accuracy: ', 0.87524)\n",
      "CPU times: user 17min 4s, sys: 2.38 s, total: 17min 7s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "best_clf_knn = KNeighborsClassifier(n_neighbors = 5 ,n_jobs=-1)\n",
    "best_clf_knn.fit(X_train, y_train)\n",
    "y_pred_knn = best_clf_knn.predict(X_test)\n",
    "acc_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print ('KNN accuracy: ',acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112.619704</td>\n",
       "      <td>0.335776</td>\n",
       "      <td>0.87440</td>\n",
       "      <td>0.999800</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 0.001, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.878239</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.876020</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.868939</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>17.632588</td>\n",
       "      <td>0.036712</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.000157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>110.268448</td>\n",
       "      <td>0.315826</td>\n",
       "      <td>0.87264</td>\n",
       "      <td>0.999780</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 0.0001, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.878479</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.873860</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.865578</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>24.472031</td>\n",
       "      <td>0.045331</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.000185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>110.449057</td>\n",
       "      <td>0.311192</td>\n",
       "      <td>0.87216</td>\n",
       "      <td>0.999720</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 1e-06, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.875720</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.873620</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.867139</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>15.233094</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>121.302371</td>\n",
       "      <td>0.303637</td>\n",
       "      <td>0.86964</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 1e-05, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>4</td>\n",
       "      <td>0.876440</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.873140</td>\n",
       "      <td>0.999940</td>\n",
       "      <td>0.859337</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>10.238262</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.000075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>108.475562</td>\n",
       "      <td>0.397572</td>\n",
       "      <td>0.86644</td>\n",
       "      <td>0.995220</td>\n",
       "      <td>0.1</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 0.1, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>5</td>\n",
       "      <td>0.871641</td>\n",
       "      <td>0.992199</td>\n",
       "      <td>0.864138</td>\n",
       "      <td>0.996160</td>\n",
       "      <td>0.863538</td>\n",
       "      <td>0.997300</td>\n",
       "      <td>18.776221</td>\n",
       "      <td>0.033016</td>\n",
       "      <td>0.003687</td>\n",
       "      <td>0.002186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>128.627861</td>\n",
       "      <td>0.323527</td>\n",
       "      <td>0.86408</td>\n",
       "      <td>0.994699</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(784,)</td>\n",
       "      <td>{u'alpha': 0.01, u'hidden_layer_sizes': (784,)}</td>\n",
       "      <td>6</td>\n",
       "      <td>0.854367</td>\n",
       "      <td>0.984878</td>\n",
       "      <td>0.866659</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.871219</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>17.387061</td>\n",
       "      <td>0.014816</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.006948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>94.510247</td>\n",
       "      <td>0.488114</td>\n",
       "      <td>0.86232</td>\n",
       "      <td>0.992060</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(784, 784)</td>\n",
       "      <td>{u'alpha': 1e-05, u'hidden_layer_sizes': (784,...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.863364</td>\n",
       "      <td>0.991719</td>\n",
       "      <td>0.864618</td>\n",
       "      <td>0.991001</td>\n",
       "      <td>0.858977</td>\n",
       "      <td>0.993461</td>\n",
       "      <td>7.724497</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>121.163234</td>\n",
       "      <td>0.521094</td>\n",
       "      <td>0.86000</td>\n",
       "      <td>0.992160</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(784, 784)</td>\n",
       "      <td>{u'alpha': 0.0001, u'hidden_layer_sizes': (784...</td>\n",
       "      <td>8</td>\n",
       "      <td>0.864203</td>\n",
       "      <td>0.987458</td>\n",
       "      <td>0.856337</td>\n",
       "      <td>0.993101</td>\n",
       "      <td>0.859458</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>21.900979</td>\n",
       "      <td>0.015525</td>\n",
       "      <td>0.003234</td>\n",
       "      <td>0.003518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>123.852142</td>\n",
       "      <td>0.504105</td>\n",
       "      <td>0.85928</td>\n",
       "      <td>0.992440</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(784, 784)</td>\n",
       "      <td>{u'alpha': 0.01, u'hidden_layer_sizes': (784, ...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.860725</td>\n",
       "      <td>0.988598</td>\n",
       "      <td>0.861138</td>\n",
       "      <td>0.994960</td>\n",
       "      <td>0.855977</td>\n",
       "      <td>0.993760</td>\n",
       "      <td>5.926197</td>\n",
       "      <td>0.049125</td>\n",
       "      <td>0.002341</td>\n",
       "      <td>0.002760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>96.415568</td>\n",
       "      <td>0.388992</td>\n",
       "      <td>0.85736</td>\n",
       "      <td>0.991999</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(784, 784)</td>\n",
       "      <td>{u'alpha': 1e-06, u'hidden_layer_sizes': (784,...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.852927</td>\n",
       "      <td>0.984698</td>\n",
       "      <td>0.858737</td>\n",
       "      <td>0.996640</td>\n",
       "      <td>0.860418</td>\n",
       "      <td>0.994660</td>\n",
       "      <td>2.547495</td>\n",
       "      <td>0.091916</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.005226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>55.375185</td>\n",
       "      <td>0.086666</td>\n",
       "      <td>0.82172</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(50, 50, 50)</td>\n",
       "      <td>{u'alpha': 1e-05, u'hidden_layer_sizes': (50, ...</td>\n",
       "      <td>39</td>\n",
       "      <td>0.822577</td>\n",
       "      <td>0.990999</td>\n",
       "      <td>0.822252</td>\n",
       "      <td>0.991721</td>\n",
       "      <td>0.820331</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>6.348112</td>\n",
       "      <td>0.029324</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.001945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>63.195809</td>\n",
       "      <td>0.054897</td>\n",
       "      <td>0.81976</td>\n",
       "      <td>0.996100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>{u'alpha': 0.001, u'hidden_layer_sizes': (50, ...</td>\n",
       "      <td>40</td>\n",
       "      <td>0.822337</td>\n",
       "      <td>0.994059</td>\n",
       "      <td>0.817811</td>\n",
       "      <td>0.997780</td>\n",
       "      <td>0.819131</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>4.078554</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.001901</td>\n",
       "      <td>0.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>67.436444</td>\n",
       "      <td>0.062273</td>\n",
       "      <td>0.81948</td>\n",
       "      <td>0.986761</td>\n",
       "      <td>0.01</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>{u'alpha': 0.01, u'hidden_layer_sizes': (50, 50)}</td>\n",
       "      <td>41</td>\n",
       "      <td>0.830974</td>\n",
       "      <td>0.999580</td>\n",
       "      <td>0.812530</td>\n",
       "      <td>0.983081</td>\n",
       "      <td>0.814930</td>\n",
       "      <td>0.977622</td>\n",
       "      <td>3.428947</td>\n",
       "      <td>0.008599</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.009334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60.128009</td>\n",
       "      <td>0.059267</td>\n",
       "      <td>0.81924</td>\n",
       "      <td>0.981839</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>{u'alpha': 0.0001, u'hidden_layer_sizes': (50,...</td>\n",
       "      <td>42</td>\n",
       "      <td>0.813700</td>\n",
       "      <td>0.972336</td>\n",
       "      <td>0.821291</td>\n",
       "      <td>0.984761</td>\n",
       "      <td>0.822732</td>\n",
       "      <td>0.988421</td>\n",
       "      <td>2.169058</td>\n",
       "      <td>0.007472</td>\n",
       "      <td>0.003962</td>\n",
       "      <td>0.006884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>58.887612</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.81920</td>\n",
       "      <td>0.987721</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>{u'alpha': 1e-05, u'hidden_layer_sizes': (50, ...</td>\n",
       "      <td>43</td>\n",
       "      <td>0.824976</td>\n",
       "      <td>0.994119</td>\n",
       "      <td>0.814090</td>\n",
       "      <td>0.969282</td>\n",
       "      <td>0.818531</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>4.100929</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.013239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>99.315097</td>\n",
       "      <td>0.048343</td>\n",
       "      <td>0.81896</td>\n",
       "      <td>0.999600</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{u'alpha': 0.001, u'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>44</td>\n",
       "      <td>0.824016</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>0.999760</td>\n",
       "      <td>0.817571</td>\n",
       "      <td>0.999160</td>\n",
       "      <td>6.757375</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.003695</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>83.180792</td>\n",
       "      <td>0.047356</td>\n",
       "      <td>0.81844</td>\n",
       "      <td>0.999540</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{u'alpha': 1e-06, u'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>45</td>\n",
       "      <td>0.824136</td>\n",
       "      <td>0.999280</td>\n",
       "      <td>0.813850</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>0.817331</td>\n",
       "      <td>0.999820</td>\n",
       "      <td>3.168587</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.000221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>98.124243</td>\n",
       "      <td>0.047388</td>\n",
       "      <td>0.81784</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{u'alpha': 1e-05, u'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>46</td>\n",
       "      <td>0.830734</td>\n",
       "      <td>0.999520</td>\n",
       "      <td>0.810850</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.811930</td>\n",
       "      <td>0.997120</td>\n",
       "      <td>6.402203</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.001117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100.282474</td>\n",
       "      <td>0.056674</td>\n",
       "      <td>0.81764</td>\n",
       "      <td>0.999640</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(50,)</td>\n",
       "      <td>{u'alpha': 0.0001, u'hidden_layer_sizes': (50,)}</td>\n",
       "      <td>47</td>\n",
       "      <td>0.826296</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>0.815290</td>\n",
       "      <td>0.999340</td>\n",
       "      <td>0.811330</td>\n",
       "      <td>0.999700</td>\n",
       "      <td>5.447398</td>\n",
       "      <td>0.012650</td>\n",
       "      <td>0.006332</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>58.453475</td>\n",
       "      <td>0.055354</td>\n",
       "      <td>0.81664</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1e-06</td>\n",
       "      <td>(50, 50)</td>\n",
       "      <td>{u'alpha': 1e-06, u'hidden_layer_sizes': (50, ...</td>\n",
       "      <td>48</td>\n",
       "      <td>0.825696</td>\n",
       "      <td>0.995619</td>\n",
       "      <td>0.804369</td>\n",
       "      <td>0.967603</td>\n",
       "      <td>0.819851</td>\n",
       "      <td>0.998620</td>\n",
       "      <td>4.320486</td>\n",
       "      <td>0.004429</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.013968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "18     112.619704         0.335776          0.87440          0.999800   \n",
       "26     110.268448         0.315826          0.87264          0.999780   \n",
       "42     110.449057         0.311192          0.87216          0.999720   \n",
       "34     121.302371         0.303637          0.86964          0.999860   \n",
       "2      108.475562         0.397572          0.86644          0.995220   \n",
       "10     128.627861         0.323527          0.86408          0.994699   \n",
       "37      94.510247         0.488114          0.86232          0.992060   \n",
       "29     121.163234         0.521094          0.86000          0.992160   \n",
       "13     123.852142         0.504105          0.85928          0.992440   \n",
       "45      96.415568         0.388992          0.85736          0.991999   \n",
       "..            ...              ...              ...               ...   \n",
       "38      55.375185         0.086666          0.82172          0.990000   \n",
       "19      63.195809         0.054897          0.81976          0.996100   \n",
       "11      67.436444         0.062273          0.81948          0.986761   \n",
       "27      60.128009         0.059267          0.81924          0.981839   \n",
       "35      58.887612         0.051126          0.81920          0.987721   \n",
       "16      99.315097         0.048343          0.81896          0.999600   \n",
       "40      83.180792         0.047356          0.81844          0.999540   \n",
       "32      98.124243         0.047388          0.81784          0.998700   \n",
       "24     100.282474         0.056674          0.81764          0.999640   \n",
       "43      58.453475         0.055354          0.81664          0.987281   \n",
       "\n",
       "   param_alpha param_hidden_layer_sizes  \\\n",
       "18       0.001                   (784,)   \n",
       "26      0.0001                   (784,)   \n",
       "42       1e-06                   (784,)   \n",
       "34       1e-05                   (784,)   \n",
       "2          0.1                   (784,)   \n",
       "10        0.01                   (784,)   \n",
       "37       1e-05               (784, 784)   \n",
       "29      0.0001               (784, 784)   \n",
       "13        0.01               (784, 784)   \n",
       "45       1e-06               (784, 784)   \n",
       "..         ...                      ...   \n",
       "38       1e-05             (50, 50, 50)   \n",
       "19       0.001                 (50, 50)   \n",
       "11        0.01                 (50, 50)   \n",
       "27      0.0001                 (50, 50)   \n",
       "35       1e-05                 (50, 50)   \n",
       "16       0.001                    (50,)   \n",
       "40       1e-06                    (50,)   \n",
       "32       1e-05                    (50,)   \n",
       "24      0.0001                    (50,)   \n",
       "43       1e-06                 (50, 50)   \n",
       "\n",
       "                                               params  rank_test_score  \\\n",
       "18   {u'alpha': 0.001, u'hidden_layer_sizes': (784,)}                1   \n",
       "26  {u'alpha': 0.0001, u'hidden_layer_sizes': (784,)}                2   \n",
       "42   {u'alpha': 1e-06, u'hidden_layer_sizes': (784,)}                3   \n",
       "34   {u'alpha': 1e-05, u'hidden_layer_sizes': (784,)}                4   \n",
       "2      {u'alpha': 0.1, u'hidden_layer_sizes': (784,)}                5   \n",
       "10    {u'alpha': 0.01, u'hidden_layer_sizes': (784,)}                6   \n",
       "37  {u'alpha': 1e-05, u'hidden_layer_sizes': (784,...                7   \n",
       "29  {u'alpha': 0.0001, u'hidden_layer_sizes': (784...                8   \n",
       "13  {u'alpha': 0.01, u'hidden_layer_sizes': (784, ...                9   \n",
       "45  {u'alpha': 1e-06, u'hidden_layer_sizes': (784,...               10   \n",
       "..                                                ...              ...   \n",
       "38  {u'alpha': 1e-05, u'hidden_layer_sizes': (50, ...               39   \n",
       "19  {u'alpha': 0.001, u'hidden_layer_sizes': (50, ...               40   \n",
       "11  {u'alpha': 0.01, u'hidden_layer_sizes': (50, 50)}               41   \n",
       "27  {u'alpha': 0.0001, u'hidden_layer_sizes': (50,...               42   \n",
       "35  {u'alpha': 1e-05, u'hidden_layer_sizes': (50, ...               43   \n",
       "16    {u'alpha': 0.001, u'hidden_layer_sizes': (50,)}               44   \n",
       "40    {u'alpha': 1e-06, u'hidden_layer_sizes': (50,)}               45   \n",
       "32    {u'alpha': 1e-05, u'hidden_layer_sizes': (50,)}               46   \n",
       "24   {u'alpha': 0.0001, u'hidden_layer_sizes': (50,)}               47   \n",
       "43  {u'alpha': 1e-06, u'hidden_layer_sizes': (50, ...               48   \n",
       "\n",
       "    split0_test_score  split0_train_score  split1_test_score  \\\n",
       "18           0.878239            0.999880           0.876020   \n",
       "26           0.878479            0.999880           0.873860   \n",
       "42           0.875720            0.999760           0.873620   \n",
       "34           0.876440            0.999880           0.873140   \n",
       "2            0.871641            0.992199           0.864138   \n",
       "10           0.854367            0.984878           0.866659   \n",
       "37           0.863364            0.991719           0.864618   \n",
       "29           0.864203            0.987458           0.856337   \n",
       "13           0.860725            0.988598           0.861138   \n",
       "45           0.852927            0.984698           0.858737   \n",
       "..                ...                 ...                ...   \n",
       "38           0.822577            0.990999           0.822252   \n",
       "19           0.822337            0.994059           0.817811   \n",
       "11           0.830974            0.999580           0.812530   \n",
       "27           0.813700            0.972336           0.821291   \n",
       "35           0.824976            0.994119           0.814090   \n",
       "16           0.824016            0.999880           0.815290   \n",
       "40           0.824136            0.999280           0.813850   \n",
       "32           0.830734            0.999520           0.810850   \n",
       "24           0.826296            0.999880           0.815290   \n",
       "43           0.825696            0.995619           0.804369   \n",
       "\n",
       "    split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "18            0.999940           0.868939            0.999580     17.632588   \n",
       "26            0.999940           0.865578            0.999520     24.472031   \n",
       "42            0.999940           0.867139            0.999460     15.233094   \n",
       "34            0.999940           0.859337            0.999760     10.238262   \n",
       "2             0.996160           0.863538            0.997300     18.776221   \n",
       "10            0.999340           0.871219            0.999880     17.387061   \n",
       "37            0.991001           0.858977            0.993461      7.724497   \n",
       "29            0.993101           0.859458            0.995920     21.900979   \n",
       "13            0.994960           0.855977            0.993760      5.926197   \n",
       "45            0.996640           0.860418            0.994660      2.547495   \n",
       "..                 ...                ...                 ...           ...   \n",
       "38            0.991721           0.820331            0.987281      6.348112   \n",
       "19            0.997780           0.819131            0.996460      4.078554   \n",
       "11            0.983081           0.814930            0.977622      3.428947   \n",
       "27            0.984761           0.822732            0.988421      2.169058   \n",
       "35            0.969282           0.818531            0.999760      4.100929   \n",
       "16            0.999760           0.817571            0.999160      6.757375   \n",
       "40            0.999520           0.817331            0.999820      3.168587   \n",
       "32            0.999460           0.811930            0.997120      6.402203   \n",
       "24            0.999340           0.811330            0.999700      5.447398   \n",
       "43            0.967603           0.819851            0.998620      4.320486   \n",
       "\n",
       "    std_score_time  std_test_score  std_train_score  \n",
       "18        0.036712        0.003966         0.000157  \n",
       "26        0.045331        0.005337         0.000185  \n",
       "42        0.013305        0.003652         0.000198  \n",
       "34        0.028504        0.007408         0.000075  \n",
       "2         0.033016        0.003687         0.002186  \n",
       "10        0.014816        0.007118         0.006948  \n",
       "37        0.003356        0.002418         0.001033  \n",
       "29        0.015525        0.003234         0.003518  \n",
       "13        0.049125        0.002341         0.002760  \n",
       "45        0.091916        0.003209         0.005226  \n",
       "..             ...             ...              ...  \n",
       "38        0.029324        0.000991         0.001945  \n",
       "19        0.004056        0.001901         0.001540  \n",
       "11        0.008599        0.008188         0.009334  \n",
       "27        0.007472        0.003962         0.006884  \n",
       "35        0.003974        0.004469         0.013239  \n",
       "16        0.000902        0.003695         0.000315  \n",
       "40        0.002100        0.004272         0.000221  \n",
       "32        0.002042        0.009130         0.001117  \n",
       "24        0.012650        0.006332         0.000224  \n",
       "43        0.004429        0.008998         0.013968  \n",
       "\n",
       "[48 rows x 18 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV search\n",
    "tuning_parameaters = {'hidden_layer_sizes' : [(50,), (100,), (784,), (50,50), (100,100), (784,784), (50,50,50), (100,100,100)], \n",
    "                     'alpha' : list(10.0 ** -np.arange(1, 7))}\n",
    "\n",
    "clf_mlp = MLPClassifier(random_state=0)\n",
    "mlp = GridSearchCV(clf_mlp, param_grid=tuning_parameaters, n_jobs=-1)\n",
    "mlp.fit(X_train, y_train)\n",
    "results=pd.DataFrame(mlp.cv_results_)\n",
    "results.sort_values('mean_test_score', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the alpha = 0.001 with hidden layer (784,) has the best score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_mlp = MLPClassifier(alpha=0.001,hidden_layer_sizes=(784,),random_state=0)\n",
    "best_mlp.fit(X_train,y_train)\n",
    "y_pred_best_mlp = best_mlp.predict(X_test)\n",
    "bestacc_mlp = accuracy_score(y_test, y_pred_best_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('MLP accuracy: ', 0.86536)\n"
     ]
    }
   ],
   "source": [
    "print ('MLP accuracy: ',bestacc_mlp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
